{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f55fa4b-c1e2-4747-bb65-8d3517d187df",
   "metadata": {},
   "source": [
    "# Analysis Workflow #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "032b65ba-b17a-404f-babc-86f1d531a2a5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef5ac8-5c23-4ee6-85e6-8be81ed5ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install jproperties\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jproperties import Properties\n",
    "from zipfile import ZipFile\n",
    "from mana import dars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ec9c50-6488-4960-be41-f64b583dc3a4",
   "metadata": {},
   "source": [
    "### Load properties file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9743fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "props = Properties()\n",
    "try:\n",
    "    with open('props.properties', 'rb') as config_file:\n",
    "        props.load(config_file)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    print(\"\\033[91m\\033[1m \"+\"You must provide a props.properties file\"+\" \\033[0m\\033[91m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b0a484d",
   "metadata": {},
   "source": [
    "### Load required datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the metadata file\n",
    "pheno = pd.read_csv(props.get(\"pheno\").data,sep=\"\\t\",index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac2a6a04-0394-4e35-9fda-9ed97d007fe3",
   "metadata": {},
   "source": [
    "### Compute activation frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde656e4-ef21-4ca4-af31-bfc64b9e073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rList = list(pd.read_csv(props.get(\"rListFile\").data).iloc[:,0])\n",
    "freq_table = pd.DataFrame()\n",
    "for dir in glob.iglob(props.get(\"working_path\").data+'**/full_enum',recursive=True):\n",
    "    freq_table = pd.concat([freq_table,dars.calculate_frequencies_for_dir(dir,rList = rList)])\n",
    "freq_table.insert(1,\"Condition\",np.nan)\n",
    "#fill Condition column\n",
    "for barcode in freq_table.index:\n",
    "    barcode_condition = pheno.loc[barcode,[\"compound_name\",\"sacri_period\",\"dose_level\"]]\n",
    "    freq_table.loc[barcode,\"Condition\"] = str(barcode_condition.compound_name)+\"_\"+\\\n",
    "        str(barcode_condition.dose_level)+\"_\"+\\\n",
    "            str(barcode_condition.sacri_period).replace(\" hr\",\"h\")+\"_freq\"\n",
    "# #merge replicates\n",
    "freq_table = freq_table.groupby('Condition').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load controls for all the tested chemicals in our study\n",
    "#for testing purpose only, get modelisation results and unzip them\n",
    "with ZipFile(props.get(\"working_path\").data+\"input_data/test_data/all_controls_24hr.zip\", 'r') as zObject:\n",
    "      zObject.extractall(\n",
    "                  path=props.get(\"working_path\").data+\\\n",
    "                  \"control_24_hr/full_enum/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedb0491",
   "metadata": {},
   "source": [
    "### Compute baseline noise (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool control enumerated solutions per molecule and time,then compute activation frequencies\n",
    "freq_ctrls = dars.calculate_freq_ctrls(props.get(\"rListFile\").data, props.get(\"all_cpds\").data, \\\n",
    "    props.get(\"time\").data, pheno, props.get(\"working_path\").data)\n",
    "#for each vehicle, compute all combinations\n",
    "condition_metadata = pheno[pheno[\"compound_name\"].isin(str(props.get(\"all_cpds\").data).split('/'))][(pheno[\"sacri_period\"] == props.get(\"time\").data)\\\n",
    "     & (pheno[\"dose_level\"] == \"Control\")]\n",
    "if \"noise_data\" not in os.listdir(props.get(\"working_path\").data+\"input_data/\"):\n",
    "    os.mkdir(props.get(\"working_path\").data+\"input_data/noise_data\")\n",
    "for vehicle in list(set(condition_metadata[\"Solvent\"])):\n",
    "    tmp_metadata = condition_metadata[condition_metadata['Solvent'] == vehicle]\n",
    "    vehicle_conditions_list =  [compound + \"_control_\"+str(props.get(\"time\").data).replace(\" \",\"_\") for compound in tmp_metadata['compound_name'].unique()]\n",
    "    combinations = pd.DataFrame(list(itertools.combinations(vehicle_conditions_list, r=2)), columns=['col1', 'col2'])\n",
    "    combinations = combinations.applymap(str)\n",
    "    ctrl_noise = pd.DataFrame()\n",
    "    for comb in range(0,combinations.shape[0]):\n",
    "        freq1 = freq_ctrls.loc[combinations.iloc[comb,0]]\n",
    "        freq2 = freq_ctrls.loc[combinations.iloc[comb,1]]\n",
    "        comb_freq = pd.concat([freq1,freq2],axis=1)\n",
    "        comb_freq.columns = [\"freq1\",\"freq2\"]\n",
    "        comb_freq = comb_freq.assign(\n",
    "            R2 = np.square((comb_freq[\"freq1\"] - comb_freq[\"freq2\"]))\n",
    "        )\n",
    "        ctrl_noise.insert(0,combinations.iloc[comb,0]+\"vs\"\\\n",
    "                          +combinations.iloc[comb,1],comb_freq.R2)\n",
    "    pd.DataFrame(ctrl_noise.transpose().median()).transpose().to_csv(\\\n",
    "        props.get(\"working_path\").data+\"input_data/noise_data/\"+\\\n",
    "            \"med_R2_\"+vehicle+\"_Control_\"+str(props.get(\"time\").data).replace(\" \",\"\")+\"_combinations.tsv\",\\\n",
    "                index=None,sep='\\t')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a3ce024-cf0d-45cd-86f7-d6926d8a4432",
   "metadata": {},
   "source": [
    "#### Extract a list of diffentially activated reactions between controls and treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa91c2-e386-41da-ad3a-3000a6a31188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO INTEGRATE THE FORMULA RMD\n",
    "## Ignore warnings (warnings from the linter for division by zero errors, which are catched in the code)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "#Iterate to compute DARs between controls and treated conditions with each molecule\n",
    "reaction_prefix = \"R_\"\n",
    "if \"DARS\" not in os.listdir(props.get(\"working_path\").data):\n",
    "    os.mkdir(props.get(\"working_path\").data+\"DARS\")\n",
    "if \"DARS_direction\" not in os.listdir(props.get(\"working_path\").data):\n",
    "    os.mkdir(props.get(\"working_path\").data+\"DARS_direction\")\n",
    "\n",
    "for molecule in str(props.get(\"cpds\").data).split('/'):\n",
    "    indices = [s for s in list(freq_table.index) if molecule in s]\n",
    "    if len(indices) < 2:\n",
    "         raise ValueError(\"Less than two conditions for this molecule, we cannot compute DARs. Check previous steps of the workflow\")\n",
    "    if  \"Control\" not in indices[0]:\n",
    "        indices.reverse()\n",
    "    print(indices)\n",
    "    comp_freq = pd.DataFrame(freq_table.loc[[indices[0],indices[1]]]).dropna(axis=1).transpose()\n",
    "    print(comp_freq.columns)\n",
    "    comp_freq.columns = ['f_ctrl','f_treatment']\n",
    "    comp_freq.insert(loc=0, column='data_id', value=comp_freq.index)\n",
    "    #rescale and rotate\n",
    "    comp_freq = dars.rescale_and_rotate(comp_freq)\n",
    "    #compute scores\n",
    "    comp_freq = dars.compute_scores(comp_freq)\n",
    "    DAR_direction = {}\n",
    "    for reaction in comp_freq.data_id:\n",
    "        if comp_freq.loc[reaction].R2 > float(props.get(\"cutoff\").data):\n",
    "            if((comp_freq.loc[reaction,\"f_treatment\"]>comp_freq.loc[reaction,\"f_ctrl\"])):\n",
    "                  DAR_direction[reaction_prefix+reaction] = \"UP\"\n",
    "            elif((comp_freq.loc[reaction,\"f_treatment\"]<comp_freq.loc[reaction,\"f_ctrl\"])):\n",
    "                  DAR_direction[reaction_prefix+reaction] = \"DOWN\"\n",
    "            else:\n",
    "                  DAR_direction[reaction_prefix+reaction] = \"UNDETERMINED\" \n",
    "    if str(props.get(\"baseline_noise_filtering\").data) == \"True\":\n",
    "        DAR_list_filtered = {}\n",
    "        #filter according to associated vehicule and time noise\n",
    "        noise = pd.read_csv(props.get(\"working_path\").data+\"input_data/noise_data/med_R2_\"+\\\n",
    "                            pheno[pheno[\"compound_name\"] == molecule].Solvent.unique()[0]+\\\n",
    "                                \"_Control_\"+str(props.get(\"time\").data).replace(\" \",\"\")+\\\n",
    "                                    \"_combinations.tsv\",sep=\"\\t\").transpose()\n",
    "        for reaction in DAR_direction.keys():\n",
    "            if comp_freq.loc[reaction.replace(reaction_prefix,\"\")].R2 > noise.loc[reaction.replace(reaction_prefix,\"\"),0]*2:\n",
    "                 DAR_list_filtered[reaction] = DAR_direction[reaction]\n",
    "        pd.DataFrame(DAR_list_filtered.keys()).to_csv(props.get(\"working_path\").data+\"/DARS/\"+molecule+\\\n",
    "                                      '_'+str(props.get(\"time\").data).replace(\" \",\"_\")+\\\n",
    "                                        '_'+str(props.get(\"cond\").data)+'noise_filtered.tsv','\\t',index=None, header=None)\n",
    "        pd.DataFrame([DAR_list_filtered]).transpose().to_csv(props.get(\"working_path\").data+\"/DARS_direction/\"+molecule+\\\n",
    "                                '_'+str(props.get(\"time\").data).replace(\" \",\"_\")+\\\n",
    "                                '_'+str(props.get(\"cond\").data)+'noise_filtered.tsv','\\t', header=None)\n",
    "    else:\n",
    "        pd.DataFrame(DAR_direction.keys()).to_csv(props.get(\"working_path\").data+\"/DARS/\"+molecule+\\\n",
    "            '_'+str(props.get(\"time\").data).replace(\" \",\"_\")+\\\n",
    "                '_'+str(props.get(\"cond\").data)+'.tsv','\\t',index=None, header=None)\n",
    "        pd.DataFrame([DAR_direction]).transpose().to_csv(props.get(\"working_path\").data+\"/DARS_direction/\"+molecule+\\\n",
    "            '_'+str(props.get(\"time\").data).replace(\" \",\"_\")+\\\n",
    "                '_'+str(props.get(\"cond\").data)+'.tsv','\\t', header=None)\n",
    "#reset warning parameter:\n",
    "warnings.filterwarnings(action='default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
